{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9911c7cc-39bc-4ae3-b053-d36b9d15b658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6360b383-652f-4aa6-9bad-f8c36ddba5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = Path.cwd().parent / 'data'\n",
    "SUMM_FOLDER = DATA / 'summaries_finetune'\n",
    "TEXT_FILES = SUMM_FOLDER / 'text_files_copy'\n",
    "SOURCE_TEXTS = SUMM_FOLDER / 'source_texts_clean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5ae0159-7cec-42d0-8f15-92034ab94d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open(DATA / 'source_dict.txt', 'r')\n",
    "source_dict = json.loads(data.read())\n",
    "source_texts = list(source_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6d495469-35f1-42a6-ba07-5aa1fd6aaa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric, Dataset, Value, ClassLabel, Features, DatasetDict\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from transformers import LongformerTokenizer, LongformerForSequenceClassification, LongformerConfig\n",
    "from transformers import DataCollatorForLanguageModeling, LongformerForMaskedLM\n",
    "\n",
    "import torch\n",
    "seed = 42\n",
    "max_length = 4096\n",
    "model_name = 'allenai/longformer-base-4096'\n",
    "tokenizer = LongformerTokenizer.from_pretrained(model_name, model_max_length = max_length)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "\n",
    "def tokenizeForMLM(batch):\n",
    "    return tokenizer(batch['text'], return_special_tokens_mask = True, truncation=True)\n",
    "\n",
    "mlm_df = df[['text']].dropna()\n",
    "ds = Dataset.from_pandas(mlm_df, preserve_index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "700156fd-fcd6-4045-a910-6ed12d02fecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e53d4b35eb4966a9b826c55f277761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733833ffaa054ae3a9f23c5714142132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "039cfc3bb4e649cca274be8e8595bdbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlm_ds = ds.map(tokenizeForMLM, batched=True)\n",
    "\n",
    "# this generates labels by copying the input ids\n",
    "def group_texts(examples):\n",
    "    examples[\"labels\"] = examples[\"input_ids\"].copy()\n",
    "    return examples\n",
    "\n",
    "mlm_ds = mlm_ds.map(group_texts, batched=True)\n",
    "\n",
    "# this generates labels by copying the input ids\n",
    "def group_texts(examples):\n",
    "    examples[\"labels\"] = examples[\"input_ids\"].copy()\n",
    "    return examples\n",
    "\n",
    "mlm_ds = mlm_ds.map(group_texts, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "10c61917-b2b8-4782-917c-031c2b1ead2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'input_ids', 'special_tokens_mask', 'attention_mask', 'labels'],\n",
       "        num_rows: 78543\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['text', 'input_ids', 'special_tokens_mask', 'attention_mask', 'labels'],\n",
       "        num_rows: 13861\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate train and valid sets\n",
    "def buildDataset(ds):\n",
    "    full_dataset = ds\n",
    "    # 70% train, 30% test\n",
    "    train_valid = full_dataset.train_test_split(test_size=0.15, seed=seed)\n",
    "    # gather everyone if you want to have a single DatasetDict\n",
    "    final_dataset = DatasetDict({\n",
    "        'train': train_valid['train'],\n",
    "        'valid': train_valid['test']})\n",
    "    return final_dataset\n",
    "mlm_ds = buildDataset(mlm_ds)\n",
    "mlm_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2ad4d85d-2deb-4863-8de9-a00a3bca6578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAlnElEQVR4nO3deXxU5dn/8c8lIOKCQAkUCApaXEAFJUXUaluxQtUK2tJiq9D+tFhrn1a7/UBt1baoj3vxcSmuuFRKqz7yU0AQxQURCItCgEiQLRAgLEIECSS5fn/MnTBJJpmZbDPg9/16zWvO3HPf51wzycw1577vc465OyIiIoekOgAREUkPSggiIgIoIYiISKCEICIigBKCiIgEzVMdQDzt27f3bt26pToMEZEDyvz587e4e0YybdI+IXTr1o3s7OxUhyEickAxszXJtlGXkYiIAEoIIiISKCGIiAighCAiIoESgoiIAEoIIiISKCGIiAighBBXYVExU5dsTHUYB5w5n25lxaaiVIeRFqblbGTzzj2pDkMkLiWEOIY/NZdfPD+fXcUlqQ7lgPKjcR/ynQfeTXUYKVdSWsbI5+YzbNyHqQ5FJC4lhDjyt+0GoFQXEpI6KP+vWRv+j0TSWcIJwcyamdlCM3stPG5nZtPNbEW4bxtVd7SZ5ZlZrpkNjCrva2aLw3Njzcwa9uWIiEhdJbOH8BtgWdTjUcAMd+8BzAiPMbOewDCgFzAIeMTMmoU2jwIjgR7hNqhe0YuISINJKCGYWSZwMfBEVPFgYHxYHg8MiSqf4O7F7r4KyAP6mVknoLW7z/bIhZyfjWojIiIplugewoPAH4GyqLKO7l4AEO47hPIuwLqoevmhrEtYrlouIiJpIG5CMLNLgM3uPj/BdcYaF/BaymNtc6SZZZtZdmFhYYKbFRGR+khkD+Ec4FIzWw1MAM43s+eBTaEbiHC/OdTPB7pGtc8ENoTyzBjl1bj7OHfPcvesjIykru8gIiJ1FDchuPtod890925EBovfcvcrgUnAiFBtBPBqWJ4EDDOzlmbWncjg8dzQrVRkZv3D7KLhUW1ERCTF6nPFtLuAiWZ2NbAWGArg7jlmNhFYCpQA17t7aWhzHfAM0AqYEm4iIpIGkkoI7j4TmBmWtwIDaqg3BhgTozwbOCXZIEVEpPHpSGUREQGUEEREJFBCEBERQAlBREQCJQQREQGUEEREJFBCEBERQAlBREQCJQQREQGUEEREJFBCEBERQAlBREQCJQQREQGUEEREJFBCEBERQAlBREQCJQQREQGUEEREJFBCEBERQAlBRESCuAnBzA4zs7lm9pGZ5ZjZ7aH8NjNbb2aLwu2iqDajzSzPzHLNbGBUeV8zWxyeG2tm1jgvS0REktU8gTrFwPnu/rmZtQDeN7Mp4bkH3P3e6Mpm1hMYBvQCOgNvmtkJ7l4KPAqMBD4EJgODgCmIiEjKxd1D8IjPw8MW4ea1NBkMTHD3YndfBeQB/cysE9Da3We7uwPPAkPqFb2IiDSYhMYQzKyZmS0CNgPT3X1OeOpXZvaxmT1lZm1DWRdgXVTz/FDWJSxXLY+1vZFmlm1m2YWFhYm/GhERqbOEEoK7l7p7HyCTyK/9U4h0/xwP9AEKgPtC9VjjAl5LeaztjXP3LHfPysjISCREERGpp6RmGbn7Z8BMYJC7bwqJogx4HOgXquUDXaOaZQIbQnlmjHIREUkDicwyyjCzNmG5FXABsDyMCZS7DFgSlicBw8yspZl1B3oAc929ACgys/5hdtFw4NWGeykiIlIficwy6gSMN7NmRBLIRHd/zcyeM7M+RLp9VgPXArh7jplNBJYCJcD1YYYRwHXAM0ArIrOLNMNIRCRNxE0I7v4xcHqM8qtqaTMGGBOjPBs4JckYRUSkCehIZRERAZQQREQkUEIQERFACUFERAIlBBERAZQQREQkUEIQERFACUFERAIlBBERAZQQRBqV13blEJE0o4Qg0gR0sVg5ECghiIgIoIQgIiKBEoKIiABKCCIiEighiIgIoIQgIiKBEoKIiABKCCIiEsRNCGZ2mJnNNbOPzCzHzG4P5e3MbLqZrQj3baPajDazPDPLNbOBUeV9zWxxeG6smQ7XERFJF4nsIRQD57t7b6APMMjM+gOjgBnu3gOYER5jZj2BYUAvYBDwiJk1C+t6FBgJ9Ai3QQ33UkREpD7iJgSP+Dw8bBFuDgwGxofy8cCQsDwYmODuxe6+CsgD+plZJ6C1u892dweejWojIiIpltAYgpk1M7NFwGZgurvPATq6ewFAuO8QqncB1kU1zw9lXcJy1fJY2xtpZtlmll1YWJjEyxERkbpKKCG4e6m79wEyifzaP6WW6rHGBbyW8ljbG+fuWe6elZGRkUiIIiJST0nNMnL3z4CZRPr+N4VuIML95lAtH+ga1SwT2BDKM2OUSxraVVzCvtKyVIchIk0okVlGGWbWJiy3Ai4AlgOTgBGh2gjg1bA8CRhmZi3NrDuRweO5oVupyMz6h9lFw6PaSJrpdesbjHhqbqrDOGjoughyIGieQJ1OwPgwU+gQYKK7v2Zms4GJZnY1sBYYCuDuOWY2EVgKlADXu3tpWNd1wDNAK2BKuEma+mDl1lSHcMDTxGo5kMRNCO7+MXB6jPKtwIAa2owBxsQozwZqG3/40isuKaVl82bxK4qINDAdqZxGcjcWceItU3nt46YdWnl/xRb+8c7KJt2miKQfJYQ0krNhBwAzlm2OU7NhXfnkHO6csrxJtyki6UcJAXj3k0J63DyZnXv2pToUkVq9vCCfJ99fleow5CClhACMnbGCfaVO7saiVIciUqvfTvyIv762NNVhyEFKCSGFcjcWseGzL1IdhtRDWZkzYe5aHbMhcZWUlpG3+fP4FVNICSGFBj74Lmff9Vaqw4jr5D9N5SdPfJjqMNLSSwvyGfXyYh6beeAPypeVOT3/PJUX566tsU7uxiLGvbuSgh1fsGJT6vao+/xlGje9srjWOgvXbqfbqNdZuHZ7E0VVu3um5XLB/e+wesuuVIdSoy9VQnB3puVspLRMRwkl44t9pczKS49jEopLShn/wWrK0uRvuHNPCQCbivZw15TlFDXRONTM3M3c80bDTgRYWrCT3XtLuW1STo11vvfQ+9wxeTln3fkW33ng3QbdfjI+272Pf86pOXEBzMwtrHSfavNWbQNg667iFEdSsy9VQpi6ZCMjn5vPuHc/TXUolSTb3fDCnDUU7EivrqbSMmfe6m2Nvp3/eSuPWyfl8MrC9Y2+rWS8vGA9j72zkvumfdKg611Z+DmvLMyvVv7Tp+fx8NsNu1dyyUPvx62z9wDsGvv7jBWceIuOgU3EQZsQ8rfv5s2lmyqVbS6KZOb6fJm+v2ILe0tq/1Cc/pdpPPx2XsLr7PXnNxKuu+XzYm5+ZUnanVbisXdWMvSx2XyQt6VRt7OsYCcAu/aWNOp2klVSGtljaeixhO/c/w43/uujGp9/Yc6aGp8rLXN++cJ8Fq37rEFjilZcUhq/UgMq2PEFPf88Nel2xXE+sxJx0CaE7z74Htc8m92g61ycv4Mrn5zDHZOX1Vpv++593PNGbsLrLf/VFd2VNW/1Nj6J0Udb3lWyfXfNXROTFxfQbdTrbNu1N+EYErGjlm2uDINlBTv21Hs7v/rnAu6csv89Xv/ZF9w/LRd3581wjEZTnRFi3uptCc0+89gn7q23eD1jN7+yhDVbY/dJb9y5h8mLNzLk4VmNENn+7QO880khO75o/O6yaTmb2L23aZNQQ6npTzktZyN79qXHazpoE0JRccP/gty+O/IFu7Kw4WcKLFi7nT/85+OKx0Mfm82FCfbR5m4sotuo1yu+GJ6eFZmnHmtGw/Zde+k26vU6JYzef5mWVH2AwqLk+0tf+7iAf7zzacXexnXPz2fsW3msiH49TXSSoKGPzWbggzX/HRo6inXbdrNk/Y6k2uwrTd14yuyVW9n6eTEjnprLL1+Yn7I4Ytnyeez/vZLSMm7816Imn/Gz/wSH+/9rsldvY+Rz8znpT8nv9TSGgzYh1MfGHXvoNup1ZjVg98eygp10G/U689fE7mefXY8Tyb20INLHPHXJxrh134t6Te9+0viDbV8f82ad2/74iTkAFb+eKg12uvPm0k14AqcRvW1SDi/Nr94Pn47OvfvthPryG9slD73HbyYsTKhu+R7uys2Jz555O3czE+eti1+xjnI27OCFGgadczbs5JWF6/ntxEUJr2/7rr388LHZbAx7wJuL9tR59lL0b5nPatnrTgUlBKrvyr2+uACAn4QvJIDifWUVu6rvrUg+Uby3IvLl+/KC9azbtrvWuokOmH5eXML90z+p6L+evnQT3Ua9zsad9e+2aQrbdu2N+ystuo86+uyrL85dxzXPZvOfBL7on/lgNb/7d6Qf/s2lmxj62AcViWT33hLun5Ybd1xoX2lZQsmnNh/kbWHw/7zf4OMMP378w7jxJ2vJ+p28uqjxzqn1s6fn8ceXPo5fsYpYf4M9+0orblOXRD67ifz6L997LSktY+Ha7Wwu2lNj99t/5uczd/U2+t85A4CL/v4elz3yQb1nu6XbZ1UJIUp54o71hX3+fTP5xfP7d4l3Rw1q7ist4wePfsC7nxTG/bJ/Yc5azr377Xr3GRYWFXPP1OWMnbGCSR9FPrjZa7aH+Bt3BtLekrJq3Ro5G3YmvZ4LH3iHC+5/J+62YtkQJgaUTxRwd55479OK80HFcvkjs7jm2Wzmrd5e8av24bfzGPtWHhPm1T6FscfNU7hrat2neZaUOT9+Yg4f5e+o+JVZm1FJfFluLiquGGyvSf87ZrDl82J2FZfw9zdXUFJLUooegI0ey4ll/Wdf8Nsqg95Tl0TGsC5/ZBaPhZMmlpY5f3ttacX/akOZmbuZk/40ldNum8bt/28pv3h+AQsS/OVePt513/RPuOyRD+g3ZgbfvGdmQm23fB7pbr3l1SV1ijuyjmJu+d+6t28MX8qEsKu4lMEPz+LZ2asTblO0p/KYxFVP7p/lk7uxiOw12xn+1FzOvfvtam0XrN1O7sbKv1gmZie+u7xqyy7WxziiuXxPpaZfnD/8x2xmLIvMtNqzr7TauZpu+NcipoS9oZq8vbz6ifZunZTDJQ+9zztRXU65cQ5Sev7DNfT96/RKZeUfqrqo2nf/0oL1/O31ZVw8dn93ywtz1tBt1OsVjxes/axSm9sm5VRM3SxPPDu+2Fdj3/OLtcx7T2bnobikjL0lZazZuqvG8YIJ89bF/XGRjI079/DEe6u4d1ouD7z5Ca8u2sC1z2XH/cL/xzuf1jqZAGD2p1srtjF75VZ+8fwCIPJ+3zVlOTt27+P4mybzxPur+PWLC/lg5f497Prudf306XlApNsqf3vk/ar6Wa0qeot7S8p4NMmDCj/8dP+earxjIfaW7I+r6ivd3sCTPhpCIhfIOWjcGvqgy/vcP1r3GcPP6lbxT7khxi+3mgan54df4y/MWVMx06Imlz/yQbWyql9o79TQn5+9ehs/eGw2AKvvurjSc5+GIx5rm91x9fhsVt91Mb1vn0ZxSRlf79a20vPxTpT2s2fmVXr8/IdrKo5kHfHUXM7s3q7i13q56C9hiOySl/8S2rxzD0cd1oJWh8a+5kOsL4hY3xlWZVA51hfrA9NrPybgmQ9WV9v26X+ZRplXf69jWbt1d8UEg9IaujJiDRZW3SuqaVvJnGxx0kcb+NvrS/n3L86utd7Ts1YDkT26N3IiPxZGf/fkWtvEem01ueLx6ke0/yu78pfmik37fxw9NWs1F5zcgTKH7u2PqHG9C9ZuZ+yMFXzja+1rrFP+A+nht/P4yZnHJBRvTQeJuTsPv53H5Wdk0rlNK6Yt3T8+N2xc4kft/9+XPuaVheuZesO5fBSm/9Y0EWHK4gK+e2qnhNfdGA76hHDWnTOYPTrmdXyq+fWLC7m0d+eE112w44tak8EXe0sTnpE0d1XswebHGug6BeXdAPNW1747vWDtdr5yxKE1Pl91F3dOlbhLyqrvrUTPZup3xwx6Zx7NkNO7xFx/rAS1JsYv5X219Jl/+96ZPP3Tr9f4PMC9VaYFu8PYGXkV0zyPv2lytSPad+4p4aEZKzi5U2uAStOaq35nbv28mL5/S2xA/aon53DzxSdT9a17bvb+YwyembWKzm1a1biO8vctb3MRx2ccyX3TPuGcKl+e5eNYAK8u2j9O9frHBfToeGSN635z2SZ+mNU15jToRNwxuXJX261RkwP++trSipP1PXZlXwb26khpmWNmNDsk8tX56xcXVnQ1JXLU8dxV2/hxv+oJobComCufmMPvLjyh1vaTFxdwTLvDuXfaJ0xfuomjDz+01s/NB3lbOPtr7ZmVt4X/nrqch644nRbNDqFzm1bMzI3sYQ968L2K+jNzC2l3xKHkV9nr/68XF5KX4oRg9d1la2xZWVmenZ388QTRv1Ln3DSAjq0Pq/bLFeCGC3owdclGloe55v/nnO6UuVf79RhzG185nNVba96tv+jUrzJ5ceyZP9d/+/ikjzR9+mdfp1en1vS7Y0ZS7RK1/K+DGmX629ybBtQa88M/PoOLT4t8EIaNm82Hn+5PMi9ddzbff7T6Hla0j2+7kPunfZLQ36yh3HjBCTzwZvU9kEt7d+bbJ2XUejBZY3t8eBY/b+BjcJ7+6der7S02liMObcahzQ9h4Z8vxN3pPnpy0uu4d2hvfv/v2H+Dww9tVjFBZPbo8znrzurnE2t/ZMsauw5jWX3XxZxz11uVunav/kb3pE5V3vwQI++Oi9izL3L6kD8MPJGvHNky4fZVmdl8d89Kps1Bv4cAcOYdM+jTtU3M5x58c0Wlx0/NWsWFPTsmtN7akgHAgjWf1fhcbQeW1eRnT8/j93F+3dTH4410So94Cez6fy7g4tMi3SbRyQAqD97X5NKH3o/7t2gqkz7a0OADp8lq6GQA1bsOG9OuvaXsCl/YdZ2WubGWsxFEH9h299TYB5AmkwwAdhWXVBvnS/a6FSVlzr+z11Ucj1RS5tw7tHdS66ivuIPKZtbVzN42s2VmlmNmvwnlt5nZejNbFG4XRbUZbWZ5ZpZrZgOjyvua2eLw3Fir2hHciJI5fH9alVNe1FVtU8riDUbV5N4GPldOtPvi9Lk3pv/Mz680WFcukS+3VCSDWHsH0rCeeO9TyurYg7H+s8SmczbUObF63Zr46WdqE31wanQXX1NJZA+hBPiduy8ws6OA+WZWPl3kAXe/N7qymfUEhgG9gM7Am2Z2gruXAo8CI4EPgcnAIEBnnZIad+/37NM5aL6s/vb6Mjq2PqxObWs7hfeBYtPOpj8ratw9BHcvcPcFYbkIWAbEHhGMGAxMcPdid18F5AH9zKwT0NrdZ3tk4OJZYEh9X4CIHLz+68XEjpaWhpHUcQhm1g04HSg/hPdXZvaxmT1lZuXzGbsA0ZPs80NZl7BctTzWdkaaWbaZZRcWpse5zEVEDnYJJwQzOxJ4CbjB3XcS6f45HugDFAD3lVeN0dxrKa9e6D7O3bPcPSsjIyPREEVEpB4SSghm1oJIMnjB3V8GcPdN7l7q7mXA40C/UD0f6BrVPBPYEMozY5SLiEgaSGSWkQFPAsvc/f6o8ugjKC4Dyo9YmgQMM7OWZtYd6AHMdfcCoMjM+od1DgdebaDXISIi9ZTILKNzgKuAxWa2KJTdBFxhZn2IdPusBq4FcPccM5sILCUyQ+n6MMMI4DrgGaAVkdlFmmEkIpIm4iYEd3+f2P3/NR4+6O5jgDExyrOBU5IJUETky6q0zCtO4dEUvpRnOxURORAkcqR+Q1JCEBERQAlBREQCJQQREQGUEEREJFBCEBERQAlBREQCJQQREQGUEEREJFBCEBERQAlBREQCJQQREQGUEERE0lbMK4g1IiUEEREBlBBERCRQQhAREUAJQUREAiUEEREBlBBERCSImxDMrKuZvW1my8wsx8x+E8rbmdl0M1sR7ttGtRltZnlmlmtmA6PK+5rZ4vDcWDNruouFiohIrRLZQygBfufuJwP9gevNrCcwCpjh7j2AGeEx4blhQC9gEPCImTUL63oUGAn0CLdBDfhaRESkHuImBHcvcPcFYbkIWAZ0AQYD40O18cCQsDwYmODuxe6+CsgD+plZJ6C1u892dweejWojIiIpltQYgpl1A04H5gAd3b0AIkkD6BCqdQHWRTXLD2VdwnLV8ljbGWlm2WaWXVhYmEyIIiJSRwknBDM7EngJuMHdd9ZWNUaZ11JevdB9nLtnuXtWRkZGoiGKiEg9JJQQzKwFkWTwgru/HIo3hW4gwv3mUJ4PdI1qnglsCOWZMcpFRCQNJDLLyIAngWXufn/UU5OAEWF5BPBqVPkwM2tpZt2JDB7PDd1KRWbWP6xzeFQbERGpwpv47HbNE6hzDnAVsNjMFoWym4C7gIlmdjWwFhgK4O45ZjYRWEpkhtL17l4a2l0HPAO0AqaEm4iIpIG4CcHd3yd2/z/AgBrajAHGxCjPBk5JJkAREWkaOlJZREQAJQQREQmUEEREBFBCEBGRQAlBREQAJQQREQmUEEREBFBCEBGRQAlBREQAJQQREQmUEERE0lUTn9xOCUFERAAlBBERCZQQREQEUEIQEZFACUFERAAlBBERCZQQREQEUEIQEZEgbkIws6fMbLOZLYkqu83M1pvZonC7KOq50WaWZ2a5ZjYwqryvmS0Oz401s5qu0ywiIimQyB7CM8CgGOUPuHufcJsMYGY9gWFAr9DmETNrFuo/CowEeoRbrHWKiEiKxE0I7v4usC3B9Q0GJrh7sbuvAvKAfmbWCWjt7rPd3YFngSF1jFlERBpBfcYQfmVmH4cupbahrAuwLqpOfijrEparlsdkZiPNLNvMsgsLC+sRoojIgcub+GRGdU0IjwLHA32AAuC+UB5rXMBrKY/J3ce5e5a7Z2VkZNQxRBERSUadEoK7b3L3UncvAx4H+oWn8oGuUVUzgQ2hPDNGuYiIpIk6JYQwJlDuMqB8BtIkYJiZtTSz7kQGj+e6ewFQZGb9w+yi4cCr9YhbREQaWPN4FczsReBbQHszywduBb5lZn2IdPusBq4FcPccM5sILAVKgOvdvTSs6joiM5ZaAVPCTURE0kTchODuV8QofrKW+mOAMTHKs4FTkopORESajI5UFhERQAlBREQCJQQREQGUEEREJFBCEBERQAlBREQCJQQREQGUEERE0pY37bntlBBERCRCCUFERAAlBBERCZQQREQEUEIQEZFACUFERAAlBBERCZQQREQEUEIQEZFACUFERAAlBBERCeImBDN7ysw2m9mSqLJ2ZjbdzFaE+7ZRz402szwzyzWzgVHlfc1scXhurJlZw78cERGpq0T2EJ4BBlUpGwXMcPcewIzwGDPrCQwDeoU2j5hZs9DmUWAk0CPcqq5TRESiNPG57eInBHd/F9hWpXgwMD4sjweGRJVPcPdid18F5AH9zKwT0NrdZ7u7A89GtRERkTRQ1zGEju5eABDuO4TyLsC6qHr5oaxLWK5aLiIiaaKhB5VjjQt4LeWxV2I20syyzSy7sLCwwYITEZGa1TUhbArdQIT7zaE8H+gaVS8T2BDKM2OUx+Tu49w9y92zMjIy6hiiiIgko64JYRIwIiyPAF6NKh9mZi3NrDuRweO5oVupyMz6h9lFw6PaiIhIGmger4KZvQh8C2hvZvnArcBdwEQzuxpYCwwFcPccM5sILAVKgOvdvTSs6joiM5ZaAVPCTURE0kTchODuV9Tw1IAa6o8BxsQozwZOSSo6ERFpMjpSWUREACUEEREJlBBERARQQhARkUAJQUQkTUXO9NN0lBBERARQQhARkUAJQUREACUEEREJlBBERARQQhARkUAJQUREACUEEREJlBBERARQQhARkUAJQUREACUEEREJlBBERNJUyxbNmnR7B21CWHL7QACOzzgCgItO/WrFc52OPqxS3SNbNmfyr8/lnz8/s9p6LjmtE9d963jaH9mSK/odQ7/u7So936drG/4+rA8ALZtH3s7eXdsA0OGolvz83O6Mu6ovhzbf/1YPOKkD9w3tzXknZFRaV4tmBsB3enakZ6fW/P7CE7jo1K8yuE9nAEaed1yl1wFw00UnMe3G82h+iFWUXdizI9d8ozsjzjqW277Xk1suPpnfDOjBT8/uxh8GnkifEF+5y8/owt0/OK1S2WEtDuHu70fKvvG19gw4qQO9u7bh8jO6VHuP4unSplXF8q/P/1ql52aNOp9mh+x/3QDNDjF6dW6NGfTr3o6LT+1UsZ62h7eoaPv7C0/gnh+cxsWndWJIn87ccdmpXHJap0rr/+/vn4qFt+aOy04ls20rhvTpzB8HnQjALRefzDlf+woAx37lcIafdSzzb7mAjKNactJXjwLggpM7AHD7pb148Ed9KtZ9YsfI88O+3rXG135uj/ac3Kk19w3tzQ+zMunXrV3F/8vI847juPZHcPulvbj1ez05oeORABzX/gheuOZM/jK4F4/85IzI+zagB0P7ZnL7pb0q1n3ByR04uVNrADLbtuKvg3vx83O707Vdq0oxnH9SB444dP8Xy52XnwrA775zAgBv/e6bAJza5eiKOtd+8zhO7HgU13yjO2Zw/beP58YLTuAPA0/k+2dkVvzvtjviUAac1IFj2h3O0L6Z3FPl/wjgWydmVCv7auvDODN8lh75yRnMGnU+3dsfUeP7OKRPZ77XuzOndGnNrwf0qPT/Wv567v9hb54YnsUV/Y4B4NsnZvCPq/pW1Gt+iPH3YX0qPmflRpx1bMX3RGbbVpza5Whe+eXZ3HhB5P05LfNoTu7Umh+feUyldtd+87hKjzsc1ZK7v38arVo049rzjqt4/m9DTuGhK07nuLCNM45pU+1z3PfYtkDkb1r+9/tRVtdKf7emYE19etVkZWVleXZ2dqrDEBE5oJjZfHfPSqZNvfYQzGy1mS02s0Vmlh3K2pnZdDNbEe7bRtUfbWZ5ZpZrZgPrs20REWlYDdFl9G137xOViUYBM9y9BzAjPMbMegLDgF7AIOARM2va/SEREalRY4whDAbGh+XxwJCo8gnuXuzuq4A8oF8jbF9EROqgvgnBgWlmNt/MRoayju5eABDuO4TyLsC6qLb5oawaMxtpZtlmll1YWFjPEEVEJBHN69n+HHffYGYdgOlmtryWuhajLOaItruPA8ZBZFC5njGKiEgC6rWH4O4bwv1m4BUiXUCbzKwTQLjfHKrnA9Hz8zKBDfXZvoiINJw6JwQzO8LMjipfBi4ElgCTgBGh2gjg1bA8CRhmZi3NrDvQA5hb1+2LiEjDqk+XUUfgFYsc9dMc+Ke7TzWzecBEM7saWAsMBXD3HDObCCwFSoDr3b20XtGLiEiDSfsD08ysEFhTx+btgS0NGE5DStfY0jUuUGx1la6xpWtccHDEdqy7Vz9MvBZpnxDqw8yykz1Sr6mka2zpGhcotrpK19jSNS748sZ20J7LSEREkqOEICIiwMGfEMalOoBapGts6RoXKLa6StfY0jUu+JLGdlCPIYiISOIO9j0EERFJkBKCiIgAB2lCMLNB4ZoLeWY2qhG385SZbTazJVFlSV8Pwsz6hutK5JnZWAtH+4Wjuv8VyueYWbcE4+pqZm+b2TIzyzGz36RRbIeZ2Vwz+yjEdnu6xBbaNjOzhWb2WjrFFdo3yPVHGuFv2sbM/mNmy8P/3FlpEteJ4b0qv+00sxvSIbbQ9sbwGVhiZi9a5LOR2tjc/aC6Ac2AlcBxwKHAR0DPRtrWecAZwJKosruBUWF5FPDfYblniKUl0D3E2Cw8Nxc4i8gJAKcA3w3lvwQeC8vDgH8lGFcn4IywfBTwSdh+OsRmwJFhuQUwB+ifDrGF+r8F/gm8li5/z6jYVgPtq5SlPD4ip7m/JiwfCrRJh7hifC9sBI5Nh9iInOl5FdAqPJ4I/DTVsaX8C7yhb+GNeSPq8WhgdCNurxuVE0Iu0CksdwJyY8UBvBFi7QQsjyq/AvhHdJ2w3JzI0YlWhxhfBb6TbrEBhwMLgDPTITYiJ1ycAZzP/oSQ8rii1rWa6gkhpfEBrYl8sVk6xRUjzguBWekSG/svB9AutHstxJjS2A7GLqOEr7vQSJK9HkSXsFy1vFIbdy8BdgBfSSaYsJt4OpFf4mkRW+iWWUTkTLjT3T1dYnsQ+CNQFlWWDnGVc+p//ZGGju84oBB4OnS1PWGRk12mOq6qhgEvhuWUx+bu64F7iZzvrQDY4e7TUh3bwZgQEr7uQhOrKa7a4q3XazGzI4GXgBvcfWe6xObupe7eh8gv8n5mdkqqYzOzS4DN7j6/tnpNHVcV57j7GcB3gevN7Lw0iK85kW7TR939dGAX4bK5KY5r/wbNDgUuBf4dr2pTxRbGBgYT6f7pDBxhZlemOraDMSGk+roLyV4PIj8sVy2v1MbMmgNHA9sSCcLMWhBJBi+4+8vpFFs5d/8MmEnkGtupju0c4FIzWw1MAM43s+fTIK4K3jDXH2no+PKB/LCXB/AfIgki1XFF+y6wwN03hcfpENsFwCp3L3T3fcDLwNmpju1gTAjzgB5m1j38MhhG5FoMTSWp60GE3cIiM+sfZgcMr9KmfF0/AN7y0CFYm7CeJ4Fl7n5/msWWYWZtwnIrIh+M5amOzd1Hu3umu3cj8j/zlrtfmeq4ylkDXX+kEd63jcA6MzsxFA0gcor7tHjfgivY311UdX2pim0t0N/MDg/rHAAsS3lsyQzMHCg34CIiM2tWAjc34nZeJNL/t49INr6aSB/dDGBFuG8XVf/mEFMuYSZAKM8i8uFeCfwP+48gP4zIbm4ekZkExyUY1zeI7Bp+DCwKt4vSJLbTgIUhtiXAn0N5ymOLWu+32D+onBZxEemr/yjccsr/r9MhPqAPkB3+pv8LtE2HuELbw4GtwNFRZekS2+1EfgwtAZ4jMoMopbHp1BUiIgIcnF1GIiJSB0oIIiICKCGIiEighCAiIoASgoiIBEoIIiICKCGIiEjw/wEzfbt7YJFqaAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series([len(seq) for seq in mlm_ds['train']['input_ids']]).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3c48a26c-8965-4321-a563-717ec371cc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /home/jovyan/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/allenai/longformer-base-4096/resolve/main/pytorch_model.bin from cache at /home/jovyan/.cache/huggingface/transformers/a7a586602e625bd012d75abdfcc615f5bb1fe133273845f7381332c634273bd9.dc3a4f03d4ab11f972b126d0e6b67f43e5d9003b3aec54f8e549cc7e2d42398d\n",
      "All model checkpoint weights were used when initializing LongformerForMaskedLM.\n",
      "\n",
      "Some weights of LongformerForMaskedLM were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['lm_head.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /home/jovyan/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/allenai/longformer-base-4096/resolve/main/pytorch_model.bin from cache at /home/jovyan/.cache/huggingface/transformers/a7a586602e625bd012d75abdfcc615f5bb1fe133273845f7381332c634273bd9.dc3a4f03d4ab11f972b126d0e6b67f43e5d9003b3aec54f8e549cc7e2d42398d\n",
      "All model checkpoint weights were used when initializing LongformerForMaskedLM.\n",
      "\n",
      "Some weights of LongformerForMaskedLM were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['lm_head.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `LongformerForMaskedLM.forward` and have been ignored: text, special_tokens_mask. If text, special_tokens_mask are not expected by `LongformerForMaskedLM.forward`,  you can safely ignore this message.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 78543\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9818\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtiedaar1\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/shared/2022_09_21_textbook/src/wandb/run-20221116_212524-2ul3enq3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/tiedaar1/huggingface/runs/2ul3enq3\" target=\"_blank\">./results</a></strong> to <a href=\"https://wandb.ai/tiedaar1/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:707\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor(value):\n\u001b[0;32m--> 707\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;66;03m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[39;00m\n\u001b[1;32m    710\u001b[0m     \u001b[38;5;66;03m# # at-least2d\u001b[39;00m\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;66;03m# if tensor.ndim > 2:\u001b[39;00m\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor.squeeze(0)\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;66;03m# elif tensor.ndim < 2:\u001b[39;00m\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor[None, :]\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 1320 at dim 1 (got 869)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [85]\u001b[0m, in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     20\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     21\u001b[0m     evaluation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     28\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     29\u001b[0m     model_init\u001b[38;5;241m=\u001b[39mmodel_init,\n\u001b[1;32m     30\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator,\n\u001b[1;32m     34\u001b[0m )\n\u001b[0;32m---> 36\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1409\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1406\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1407\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1408\u001b[0m )\n\u001b[0;32m-> 1409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1410\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1414\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1625\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_rng_state(resume_from_checkpoint)\n\u001b[1;32m   1624\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1625\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(epoch_iterator):\n\u001b[1;32m   1626\u001b[0m \n\u001b[1;32m   1627\u001b[0m     \u001b[38;5;66;03m# Skip past any already trained steps if resuming training\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m steps_trained_in_current_epoch \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1629\u001b[0m         steps_trained_in_current_epoch \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    691\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    694\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/data/data_collator.py:42\u001b[0m, in \u001b[0;36mDataCollatorMixin.__call__\u001b[0;34m(self, features, return_tensors)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtf_call(features)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_tensors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_tensors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy_call(features)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/data/data_collator.py:729\u001b[0m, in \u001b[0;36mDataCollatorForLanguageModeling.torch_call\u001b[0;34m(self, examples)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtorch_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, examples: List[Union[List[\u001b[38;5;28mint\u001b[39m], Any, Dict[\u001b[38;5;28mstr\u001b[39m, Any]]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m    727\u001b[0m     \u001b[38;5;66;03m# Handle dict or lists with proper padding and conversion to tensor.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(examples[\u001b[38;5;241m0\u001b[39m], Mapping):\n\u001b[0;32m--> 729\u001b[0m         batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m         batch \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    732\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m: _torch_collate_batch(examples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer, pad_to_multiple_of\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_to_multiple_of)\n\u001b[1;32m    733\u001b[0m         }\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2894\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.pad\u001b[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[1;32m   2891\u001b[0m             batch_outputs[key] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2892\u001b[0m         batch_outputs[key]\u001b[38;5;241m.\u001b[39mappend(value)\n\u001b[0;32m-> 2894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatchEncoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:209\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    205\u001b[0m     n_sequences \u001b[38;5;241m=\u001b[39m encoding[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_sequences\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_sequences \u001b[38;5;241m=\u001b[39m n_sequences\n\u001b[0;32m--> 209\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:723\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverflowing_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    719\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    720\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor returning overflowing tokens of different lengths. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    721\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease see if a fast version of this tokenizer is available to have this feature available.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    722\u001b[0m             )\n\u001b[0;32m--> 723\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    724\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor, you should probably activate truncation and/or padding \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    725\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpadding=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtruncation=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to have batched tensors with the same length.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    726\u001b[0m         )\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length."
     ]
    }
   ],
   "source": [
    "# Show the training loss with every epoch\n",
    "\n",
    "import torch\n",
    "seed = 42\n",
    "model_name = 'allenai/longformer-base-4096'\n",
    "#torch.cuda.empty_cache()\n",
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "\n",
    "def model_init():\n",
    "    return LongformerForMaskedLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15) \n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=training_args,\n",
    "    train_dataset=mlm_ds[\"train\"],\n",
    "    eval_dataset=mlm_ds[\"valid\"],\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95803966-cb79-4eca-8a78-f0a229282416",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
